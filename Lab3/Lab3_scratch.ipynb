{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aca366da-d246-4d82-ba54-b010f2e7ecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set up code for this experiment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b2d3896-46b0-4c27-9780-3b5d93e5f5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(X_test, X_train):\n",
    "  dists = np.add(np.sum(X_test ** 2, axis=1, keepdims=True), np.sum(X_train ** 2, axis=1, keepdims=True).T) - 2* X_test @ X_train.T\n",
    "  return dists\n",
    "\n",
    "def find_k_neighbors(dists, Y_train, k):\n",
    "  \"\"\"\n",
    "  find the labels of the top k nearest neighbors\n",
    "\n",
    "  Inputs:\n",
    "  - dists: distance matrix of shape (num_test, num_train)\n",
    "  - Y_train: A numpy array of shape (num_train) containing ground truth labels for training data\n",
    "  - k: An integer, k nearest neighbors\n",
    "\n",
    "  Output:\n",
    "  - neighbors: A numpy array of shape (num_test, k), where each row containts the \n",
    "               labels of the k nearest neighbors for each test example\n",
    "  \"\"\"\n",
    "  \n",
    "  num_test = dists.shape[0]\n",
    "  neighbors = np.zeros((num_test, k))\n",
    "  sorted_idx = dists.argsort(axis=1)\n",
    "  for i in range(num_test):\n",
    "    neighbors[i] = Y_train[sorted_idx[i][:k]]\n",
    "  return neighbors\n",
    "\n",
    "def knn_predict(X_test, X_train, Y_train, k):\n",
    "  \"\"\"\n",
    "  predict labels for test data.\n",
    "\n",
    "  Inputs:\n",
    "  - X_test: A numpy array of shape (num_test, dim_feat) containing test data.\n",
    "  - X_train: A numpy array of shape (num_train, dim_feat) containing training data.\n",
    "  - Y_train: A numpy array of shape (num_train) containing ground truth labels for training data\n",
    "  - k: An integer, k nearest neighbors\n",
    "\n",
    "  Output:\n",
    "  - Y_pred: A numpy array of shape (num_test). Predicted labels for the test data.\n",
    "  \"\"\"\n",
    "  # TODO:\n",
    "  # find the labels of k nearest neighbors for each test example,\n",
    "  # and then find the majority label out of the k labels\n",
    "  #\n",
    "  # Here is the pseudo-code:\n",
    "  # dists = euclidean_dist(X_test, X_train)\n",
    "  # neighbors = find_k_neighbors(dists, Y_train, k)\n",
    "  # Y_pred = np.zeros(num_test, dtype=int)  # force dtype=int in case the dataset\n",
    "  #                                         # stores labels as float-point numbers\n",
    "  # for i = 0 ... num_test-1\n",
    "  #     Y_pred[i] = # the most common/frequent label in neighbors[i], you can\n",
    "  #                 # implement it by using np.unique\n",
    "  # return Y_pred\n",
    "\n",
    "  \n",
    "  num_test = X_test.shape[0]\n",
    "  Y_pred = np.zeros(num_test, dtype=int)\n",
    "  dists = euclidean_dist(X_test, X_train)\n",
    "  neighbors = find_k_neighbors(dists, Y_train, k)\n",
    "\n",
    "  for i in range(num_test):\n",
    "    value, counts = np.unique(neighbors[i], return_counts=True)\n",
    "    idx = np.argmax(counts)\n",
    "    Y_pred[i] = value[idx]\n",
    "\n",
    "  return Y_pred\n",
    "\n",
    "def compute_error_rate(ypred, ytrue):\n",
    "  \"\"\"\n",
    "  Compute error rate given the predicted results and true lable.\n",
    "  Inputs:\n",
    "  - ypred: array of prediction results.\n",
    "  - ytrue: array of true labels.\n",
    "    ypred and ytrue should be of same length.\n",
    "  Output:\n",
    "  - error rate: float number indicating the error in percentage\n",
    "                (i.e., a number between 0 and 100).\n",
    "  \"\"\"\n",
    "  \n",
    "  error_rate =  (ypred != ytrue).mean()*100\n",
    "  return error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7463dcfd-fb4b-4cdd-845e-dfca424efd51",
   "metadata": {},
   "source": [
    "## Lab 3 work ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "885d02e1-2909-406c-bb98-cb8798382106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set [[6, 2, 8, 0, 1, 4, 7], [5, 3, 9, 0, 1, 4, 7], [5, 3, 9, 6, 2, 8]]\n",
      "val set [[5, 3, 9], [6, 2, 8], [0, 1, 4, 7]]\n"
     ]
    }
   ],
   "source": [
    "#def split_nfold(num_examples, n):\n",
    "\"\"\"\n",
    "  Split the dataset in to training sets and validation sets.\n",
    "  Inputs:\n",
    "  - num_examples: Integer, the total number of examples in the dataset\n",
    "  - n: number of folds\n",
    "  Outputs:\n",
    "  - train_sets: List of lists, where train_sets[i] (i = 0 ... n-1) contains \n",
    "                the indices of examples for training\n",
    "  - validation_sets: List of list, where validation_sets[i] (i = 0 ... n-1) \n",
    "                contains the indices of examples for validation\n",
    "\n",
    "  Example:\n",
    "  When num_examples = 10 and n = 5, \n",
    "    the output train_sets should be a list of length 5, \n",
    "    and each element in this list is itself a list of length 8, \n",
    "    containing 8 indices in 0...9\n",
    "  For example, \n",
    "    we can initialize by randomly permuting [0, 1, ..., 9] into, say,\n",
    "      [9, 5, 3, 0, 8, 4, 2, 1, 6, 7]\n",
    "    Then we can have\n",
    "    train_sets[0] = [3, 0, 8, 4, 2, 1, 6, 7],  validation_sets[0] = [9, 5]\n",
    "    train_sets[1] = [9, 5, 8, 4, 2, 1, 6, 7],  validation_sets[1] = [3, 0]\n",
    "    train_sets[2] = [9, 5, 3, 0, 2, 1, 6, 7],  validation_sets[2] = [8, 4]\n",
    "    train_sets[3] = [9, 5, 3, 0, 8, 4, 6, 7],  validation_sets[3] = [2, 1]\n",
    "    train_sets[4] = [9, 5, 3, 0, 8, 4, 2, 1],  validation_sets[4] = [6, 7]\n",
    "  Within train_sets[i] and validation_sets[i], the indices do not need to be sorted.\n",
    "\"\"\"\n",
    "  # generate random index list\n",
    "num_examples = 10\n",
    "n = 3\n",
    "idx = np.random.permutation(num_examples).tolist() \n",
    "\n",
    "\n",
    "fold_size = num_examples//n   # compute how many examples in one fold.                            # note '//' as we want an integral result\n",
    "train_sets = []\n",
    "val_sets = []\n",
    "\n",
    "# figure out what index in what fold\n",
    "\n",
    "for i in range(n):\n",
    "    # calculate start and end for each fold size\n",
    "    start = i * fold_size\n",
    "    end = fold_size + i * fold_size\n",
    "    # if num_examples does not divide evenly\n",
    "    if i == n-1:\n",
    "        end = num_examples  # handle the remainder by allocating them to the last fold\n",
    "    \n",
    "    # Extract training indices, exclude between start and end\n",
    "    train_set = [idx[x] for x in range(num_examples) if x not in range(start,end)]\n",
    "    train_sets.append(train_set)\n",
    "    \n",
    "    # Extract validation example indices from the idx list using start and end\n",
    "    val_set = idx[start:end] \n",
    "    val_sets.append(val_set)\n",
    "\n",
    "  #avoid randomness\n",
    "np.random.seed(1) \n",
    "  \n",
    "  # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    " \n",
    "\n",
    "\n",
    "  # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    " # return train_sets, validation_sets\n",
    "\n",
    "# Unit test code here (you can uncomment the lines below to test)\n",
    "#train_sets, val_sets = split_nfold(11, 5)\n",
    "print(\"train set\", train_sets)\n",
    "print(\"val set\", val_sets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
