<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>lab_3</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="Lab_3_files/libs/clipboard/clipboard.min.js"></script>
<script src="Lab_3_files/libs/quarto-html/quarto.js"></script>
<script src="Lab_3_files/libs/quarto-html/popper.min.js"></script>
<script src="Lab_3_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Lab_3_files/libs/quarto-html/anchor.min.js"></script>
<link href="Lab_3_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Lab_3_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Lab_3_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Lab_3_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Lab_3_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">



<section id="lab-3-cross-validation" class="level2">
<h2 class="anchored" data-anchor-id="lab-3-cross-validation"><strong>Lab 3: Cross Validation</strong></h2>
<p>CS 412</p>
<p><strong><em>This lab can be conducted in groups or individually.</em></strong></p>
<p>In this lab, we will see how to implement and use cross validation <em>step by step</em>.</p>
<p><strong><em>Deadline:</em></strong> <strong>23:59, Feb 17</strong>.</p>
</section>
<section id="please-refer-to-lab_guideline.pdf-in-the-same-google-drive-folder-as-this-jupyter-notebook-the-guidelines-there-apply-to-all-the-labs." class="level2">
<h2 class="anchored" data-anchor-id="please-refer-to-lab_guideline.pdf-in-the-same-google-drive-folder-as-this-jupyter-notebook-the-guidelines-there-apply-to-all-the-labs."><font color="red"> Please refer to <code>Lab_Guideline.pdf</code> in the same Google Drive folder as this Jupyter notebook; the guidelines there apply to all the labs.</font></h2>
</section>
<section id="problem-1-implementation-of-the-k-nearest-neighbours-knn-classifier-and-cross-validation-36-points" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="problem-1-implementation-of-the-k-nearest-neighbours-knn-classifier-and-cross-validation-36-points">Problem 1: Implementation of the k-Nearest Neighbours (kNN) classifier and Cross-Validation <strong>(36 points)</strong></h2>
<p>In Problem 1, you will implement cross validation from scratch, which is a good exercise to make sure that you fully understand this algorithm. Do not use any library such as scikit-learn that already has cross validation implemented. But you can use general libraries for array and matrix operations such as numpy.</p>
<section id="implementation-of-the-k-nearest-neighbours-classifier" class="level3">
<h3 class="anchored" data-anchor-id="implementation-of-the-k-nearest-neighbours-classifier">1.1 Implementation of the k-Nearest Neighbours classifier</h3>
<p>We have already implemented kNN in Lab 2. So for completeness, we have filled in the reference code below. There is no score associated with this sub-section.</p>
<p><strong>Step 1.</strong> The kNN classifier mainly consists of two stages:</p>
<ol type="1">
<li>During training, the classifier takes the training data and simply stores it.</li>
<li>During testing, kNN classifies every test example <span class="math inline">\(x\)</span> by</li>
</ol>
<blockquote class="blockquote">
<ol type="i">
<li>finding the <span class="math inline">\(k\)</span> training examples that are most similar to <span class="math inline">\(x\)</span>;</li>
</ol>
</blockquote>
<blockquote class="blockquote">
<ol start="2" type="i">
<li>outputing the most common label among these <span class="math inline">\(k\)</span> examples.</li>
</ol>
</blockquote>
<p>To measure the similarity between samples, we commonly compute the Euclidean distance. The Euclidean distance (a.k.a. <span class="math inline">\(L_2\)</span> distance) between two examples <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span> in an <span class="math inline">\(n\)</span>-dimensional space is defined as the square root of:</p>
<p><span class="math display">\[\begin{equation}
(p_1-q_1)^2 + (p_2-q_2)^2 + ... + (p_n-q_n)^2. \tag{1}
\end{equation}\]</span></p>
<p>This term is equal to <span class="math display">\[\begin{equation}
\sum_i p_i^2 + \sum_i q_i^2 - 2 \sum_i p_i q_i. \tag{2}
\end{equation}\]</span></p>
<p>With Euclidean distance, the smaller the value, the more similar the two examples are. Actually, there are many different ways to measure the similarity, such as cosine distance, Manhattan, Chebyshev, and Hamming distance. In practice, you can choose the one that suits your problem.</p>
<p>For this lab, we will implement Equation (2) with the following <code>euclidean_dist</code> that computes the Euclidean distances. It will be called eventually by the <code>knn_predict</code> function in Step 3 below.</p>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># set up code for this experiment</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> euclidean_dist(X_test, X_train):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  dists <span class="op">=</span> np.add(np.<span class="bu">sum</span>(X_test <span class="op">**</span> <span class="dv">2</span>, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>), np.<span class="bu">sum</span>(X_train <span class="op">**</span> <span class="dv">2</span>, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>).T) <span class="op">-</span> <span class="dv">2</span><span class="op">*</span> X_test <span class="op">@</span> X_train.T</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> dists</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Step 2.</strong> Once distances are calculated, we can find the top <span class="math inline">\(k\)</span> nearest neighbors for each test example by retrieving from the dists matrix. In particular, for each test example <span class="math inline">\(x\)</span>, we can sort all the training examples by their distance to <span class="math inline">\(x\)</span> then find the <span class="math inline">\(k\)</span> most nearest neighbors.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> find_k_neighbors(dists, Y_train, k):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">  find the labels of the top k nearest neighbors</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co">  Inputs:</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co">  - dists: distance matrix of shape (num_test, num_train)</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co">  - Y_train: A numpy array of shape (num_train) containing ground truth labels for training data</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co">  - k: An integer, k nearest neighbors</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co">  Output:</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co">  - neighbors: A numpy array of shape (num_test, k), where each row containts the </span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co">               labels of the k nearest neighbors for each test example</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co">  """</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>  num_test <span class="op">=</span> dists.shape[<span class="dv">0</span>]</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>  neighbors <span class="op">=</span> np.zeros((num_test, k))</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>  sorted_idx <span class="op">=</span> dists.argsort(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_test):</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    neighbors[i] <span class="op">=</span> Y_train[sorted_idx[i][:k]]</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> neighbors</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Step 3.</strong> Finally, we can put together <code>euclidean_dist</code> and <code>find_k_neighbors</code>, so that labels can be predicted for test examples. In kNN, we take the labels of the <span class="math inline">\(k\)</span> nearest neighbors and find the most common one and assign it to the test sample.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> knn_predict(X_test, X_train, Y_train, k):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co">  predict labels for test data.</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co">  Inputs:</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co">  - X_test: A numpy array of shape (num_test, dim_feat) containing test data.</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co">  - X_train: A numpy array of shape (num_train, dim_feat) containing training data.</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co">  - Y_train: A numpy array of shape (num_train) containing ground truth labels for training data</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co">  - k: An integer, k nearest neighbors</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co">  Output:</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="co">  - Y_pred: A numpy array of shape (num_test). Predicted labels for the test data.</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="co">  """</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># </span><span class="al">TODO</span><span class="co">:</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># find the labels of k nearest neighbors for each test example,</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># and then find the majority label out of the k labels</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>  <span class="co">#</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Here is the pseudo-code:</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># dists = euclidean_dist(X_test, X_train)</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>  <span class="co"># neighbors = find_k_neighbors(dists, Y_train, k)</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Y_pred = np.zeros(num_test, dtype=int)  # force dtype=int in case the dataset</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>  <span class="co">#                                         # stores labels as float-point numbers</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>  <span class="co"># for i = 0 ... num_test-1</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>  <span class="co">#     Y_pred[i] = # the most common/frequent label in neighbors[i], you can</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>  <span class="co">#                 # implement it by using np.unique</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>  <span class="co"># return Y_pred</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>  num_test <span class="op">=</span> X_test.shape[<span class="dv">0</span>]</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>  Y_pred <span class="op">=</span> np.zeros(num_test, dtype<span class="op">=</span><span class="bu">int</span>)</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>  dists <span class="op">=</span> euclidean_dist(X_test, X_train)</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>  neighbors <span class="op">=</span> find_k_neighbors(dists, Y_train, k)</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_test):</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>    value, counts <span class="op">=</span> np.unique(neighbors[i], return_counts<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>    idx <span class="op">=</span> np.argmax(counts)</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>    Y_pred[i] <span class="op">=</span> value[idx]</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> Y_pred</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Step 4.</strong> Once we obtain the predicted labels, we need to implement a function to compare them against the true label and compute the error rate in percentage (i.e., a number between 0 and 100). In the following code block, implement the <code>compute_error_rate</code> function by following the specified inputs and output.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_error_rate(ypred, ytrue):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co">  Compute error rate given the predicted results and true lable.</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co">  Inputs:</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co">  - ypred: array of prediction results.</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co">  - ytrue: array of true labels.</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co">    ypred and ytrue should be of same length.</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co">  Output:</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co">  - error rate: float number indicating the error in percentage</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co">                (i.e., a number between 0 and 100).</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co">  """</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>  error_rate <span class="op">=</span>  (ypred <span class="op">!=</span> ytrue).mean()<span class="op">*</span><span class="dv">100</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> error_rate</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="splitting-training-data-for-cross-validation-36-points" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="splitting-training-data-for-cross-validation-36-points">1.2 Splitting training data for cross validation <strong>(36 points)</strong></h3>
<p>Cross validation is a technique in which we train our model using a subset of the available dataset and then evaluate using the complementary subset of the data. In this assignment, we use the <span class="math inline">\(n\)</span>-fold cross validation method to perform cross validation. In <span class="math inline">\(n\)</span>-fold cross validation, we evenly partition the dataset into <span class="math inline">\(n\)</span> mutually disjoint subsets (a.k.a. <em>folds</em>). We train an ML model on all but one subset (i.e., train on the union of <span class="math inline">\(n-1\)</span> folds), and then evaluate the model on the subset that was left out. The former is called <em>training subset</em>, while the latter is called <em>validation subset</em>. This process is repeated <span class="math inline">\(n\)</span> times, with a different subset reserved for evaluation (and excluded from training) each time. If the size of the dataset is not exactly divisible by <span class="math inline">\(n\)</span>, the remainder can be arbitrarily distributed into the folds.</p>
<p><strong>Step 1. (18 points)</strong> In the following code block, you will need to implement a function that partitions the dataset in to training sets and validation sets. The output should be lists of indices which indicate the training examples and validation examples. Function inputs and outputs are detailed in the code block.</p>
<p><strong>Hint:</strong> You may find random permutation useful here: <a href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.permutation.html">np.random.permutation</a></p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> split_nfold(num_examples, n):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co">  Split the dataset in to training sets and validation sets.</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co">  Inputs:</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co">  - num_examples: Integer, the total number of examples in the dataset</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co">  - n: number of folds</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co">  Outputs:</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co">  - train_sets: List of lists, where train_sets[i] (i = 0 ... n-1) contains </span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co">                the indices of examples for training</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co">  - validation_sets: List of list, where validation_sets[i] (i = 0 ... n-1) </span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="co">                contains the indices of examples for validation</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co">  Example:</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co">  When num_examples = 10 and n = 5, </span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co">    the output train_sets should be a list of length 5, </span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="co">    and each element in this list is itself a list of length 8, </span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="co">    containing 8 indices in 0...9</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="co">  For example, </span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="co">    we can initialize by randomly permuting [0, 1, ..., 9] into, say,</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="co">      [9, 5, 3, 0, 8, 4, 2, 1, 6, 7]</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a><span class="co">    Then we can have</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a><span class="co">    train_sets[0] = [3, 0, 8, 4, 2, 1, 6, 7],  validation_sets[0] = [9, 5]</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a><span class="co">    train_sets[1] = [9, 5, 8, 4, 2, 1, 6, 7],  validation_sets[1] = [3, 0]</span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a><span class="co">    train_sets[2] = [9, 5, 3, 0, 2, 1, 6, 7],  validation_sets[2] = [8, 4]</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a><span class="co">    train_sets[3] = [9, 5, 3, 0, 8, 4, 6, 7],  validation_sets[3] = [2, 1]</span></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a><span class="co">    train_sets[4] = [9, 5, 3, 0, 8, 4, 2, 1],  validation_sets[4] = [6, 7]</span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a><span class="co">  Within train_sets[i] and validation_sets[i], the indices do not need to be sorted.</span></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a><span class="co">  """</span></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>  <span class="co"># generate random index list</span></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>  <span class="co"># fold_size = num_examples//n   # compute how many examples in one fold.</span></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>  <span class="co">#                               # note '//' as we want an integral result</span></span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>  <span class="co"># train_sets = []</span></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>  <span class="co"># validation_sets = []</span></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>  <span class="co"># for i = 0 ... n-1</span></span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>  <span class="co">#   start = # compute the start index of the i-th fold</span></span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>  <span class="co">#   end = # compute the end index of the i-th fold</span></span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>  <span class="co">#   if i == n-1</span></span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>  <span class="co">#     end = num_examples  # handle the remainder by allocating them to the last fold</span></span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>  <span class="co">#   For example, when num_examples = 11 and n = 5, </span></span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>  <span class="co">#     fold_size = 11//5 = 2</span></span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>  <span class="co">#     i = 0: start = 0, end = 2</span></span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>  <span class="co">#     i = 1: start = 2, end = 4</span></span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>  <span class="co">#     i = 2: start = 4, end = 6</span></span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>  <span class="co">#     i = 3: start = 6, end = 8</span></span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>  <span class="co">#     i = 4: start = 8, end = 11  (take up the remainder of 11//5)</span></span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>  <span class="co">#</span></span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>  <span class="co">#   # Now extract training example indices from the idx list using start and end</span></span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>  <span class="co">#   train_set = idx[`0 to num_example-1` except `start to end-1`]  </span></span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>  <span class="co">#   train_sets.append(train_set)</span></span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a>  <span class="co">#</span></span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a>  <span class="co">#   # Extract validation example indices from the idx list using start and end</span></span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>  <span class="co">#   val_set = idx[start to end-1] </span></span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a>  <span class="co">#   validation_sets.append(val_set)</span></span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a>  <span class="co">#avoid randomness</span></span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a>  np.random.seed(<span class="dv">1</span>) </span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a>  <span class="co"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a>  <span class="co"># create list of num_examples size with random indices</span></span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a>  idx <span class="op">=</span> np.random.permutation(num_examples).tolist() </span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a>  <span class="co"># find fold size</span></span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a>  fold_size <span class="op">=</span> num_examples<span class="op">//</span>n   <span class="co"># compute how many examples in one fold.                            # note '//' as we want an integral result</span></span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a>  <span class="co"># intialize train_sets</span></span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a>  train_sets <span class="op">=</span> []</span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a>  <span class="co"># initialize val_sets</span></span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a>  validation_sets <span class="op">=</span> []</span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true" tabindex="-1"></a>  <span class="co"># find training and val sets for each fold</span></span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true" tabindex="-1"></a>    <span class="co"># calculate start and end for each fold size</span></span>
<span id="cb6-74"><a href="#cb6-74" aria-hidden="true" tabindex="-1"></a>    start <span class="op">=</span> i <span class="op">*</span> fold_size</span>
<span id="cb6-75"><a href="#cb6-75" aria-hidden="true" tabindex="-1"></a>    end <span class="op">=</span> fold_size <span class="op">+</span> i <span class="op">*</span> fold_size</span>
<span id="cb6-76"><a href="#cb6-76" aria-hidden="true" tabindex="-1"></a>    <span class="co"># if num_examples does not divide evenly</span></span>
<span id="cb6-77"><a href="#cb6-77" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> i <span class="op">==</span> n<span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb6-78"><a href="#cb6-78" aria-hidden="true" tabindex="-1"></a>        end <span class="op">=</span> num_examples  <span class="co"># handle the remainder by allocating them to the last fold</span></span>
<span id="cb6-79"><a href="#cb6-79" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-80"><a href="#cb6-80" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extract training indices, exclude between start and end</span></span>
<span id="cb6-81"><a href="#cb6-81" aria-hidden="true" tabindex="-1"></a>    train_set <span class="op">=</span> [idx[x] <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(num_examples) <span class="cf">if</span> x <span class="kw">not</span> <span class="kw">in</span> <span class="bu">range</span>(start,end)]</span>
<span id="cb6-82"><a href="#cb6-82" aria-hidden="true" tabindex="-1"></a>    train_sets.append(train_set)</span>
<span id="cb6-83"><a href="#cb6-83" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-84"><a href="#cb6-84" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extract validation example indices from the idx list using start and end</span></span>
<span id="cb6-85"><a href="#cb6-85" aria-hidden="true" tabindex="-1"></a>    val_set <span class="op">=</span> idx[start:end] </span>
<span id="cb6-86"><a href="#cb6-86" aria-hidden="true" tabindex="-1"></a>    validation_sets.append(val_set)</span>
<span id="cb6-87"><a href="#cb6-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-88"><a href="#cb6-88" aria-hidden="true" tabindex="-1"></a>  <span class="co"># *****</span><span class="re">END</span><span class="co"> OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span>
<span id="cb6-89"><a href="#cb6-89" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> train_sets, validation_sets</span>
<span id="cb6-90"><a href="#cb6-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-91"><a href="#cb6-91" aria-hidden="true" tabindex="-1"></a><span class="co"># Unit test code here (you can uncomment the lines below to test)</span></span>
<span id="cb6-92"><a href="#cb6-92" aria-hidden="true" tabindex="-1"></a>train_sets, val_sets <span class="op">=</span> split_nfold(<span class="dv">11</span>, <span class="dv">5</span>)</span>
<span id="cb6-93"><a href="#cb6-93" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(train_sets)</span>
<span id="cb6-94"><a href="#cb6-94" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(val_sets)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[4, 9, 1, 6, 0, 7, 10, 8, 5], [2, 3, 1, 6, 0, 7, 10, 8, 5], [2, 3, 4, 9, 0, 7, 10, 8, 5], [2, 3, 4, 9, 1, 6, 10, 8, 5], [2, 3, 4, 9, 1, 6, 0, 7]]
[[2, 3], [4, 9], [1, 6], [0, 7], [10, 8, 5]]</code></pre>
</div>
</div>
<p><strong>Step 2. (18 points)</strong> Next, you will need to implement the <code>cross_validation</code> function, which will output the cross validation error rate. You may want to call previously defined functions such as <code>split_nfold</code> and <code>compute_error_rate</code>. In this function, you need to loop over each of the <span class="math inline">\(n\)</span> training/validation partitions in the output of <code>split_nfold</code>. Then perform training on train_sets[i] and compute the test error on validation_sets[i]. The final cross validation error rate is the average error rate over all partitions.</p>
<p>To improve generality, <code>cross_validation</code> takes as its first input argument a generic <em>classifier</em> function. In this lab, we will use kNN, and <em>classifier</em> should be instantiated by the <code>knn_predict</code> function that is implemented above. In general, the <em>classifier</em> function should conform with a prescribed protocol of prototype, i.e., what the input and output arguments are. For example its inputs are <code>(X_test, X_train, Y_train, k)</code> and its output is <code>Y_pred</code>.</p>
<p><strong>Hint:</strong> You may need to know how to use <a href="https://book.pythontips.com/en/latest/args_and_kwargs.html">*args</a></p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> cross_validation(classifier, X, Y, n, <span class="op">*</span>args):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co">  Perform cross validation for the given classifier, </span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co">      and return the cross validation error rate.</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co">  Inputs:</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co">  - classifier: function of classification method</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co">  - X: A 2-D numpy array of shape (num_train, dim_feat), containing the whole dataset</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co">  - Y: A 1-D numpy array of length num_train, containing the ground-true labels</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co">  - n: number of folds</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co">  - *args: parameters needed by the classifier.</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="co">        In this assignment, there is only one parameter (k) for the kNN clasifier.</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="co">        For other classifiers, there may be multiple paramters. </span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="co">        To keep this function general, </span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="co">        let's use *args here for an unspecified number of paramters.</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="co">  Output:</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="co">  - error_rate: a floating-point number indicating the cross validation error rate</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a><span class="co">  """</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Here is the pseudo code:</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># errors = []</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>  <span class="co"># size = X.shape[0] # get the number of examples</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>  <span class="co"># train_sets, val_sets = split_nfold(size, n)  # call the split_nfold function</span></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>  <span class="co">#</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>  <span class="co"># for i in range(n):</span></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>  <span class="co">#   train_index = train_sets[i]</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>  <span class="co">#   val_index = val_sets[i]</span></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>  <span class="co">#   # get the training and validation sets of input features from X</span></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>  <span class="co">#     X_train, X_val = X[...], X[...] </span></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>  <span class="co">#</span></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>  <span class="co">#   # get the training and validation labels from Y</span></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>  <span class="co">#     y_train, y_val = Y[...], Y[...] </span></span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>  <span class="co">#</span></span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>  <span class="co">#   # call the classifier to get prediction results for the current validation set</span></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>  <span class="co">#     ypred = # call classifier with X_val, X_train, y_train, and *args</span></span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>  <span class="co">#                                   </span></span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>  <span class="co">#     error = # call compute_error_rate to compute the error rate by comparing ypred against y_val</span></span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>  <span class="co">#     append error to the list `errors`</span></span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>  <span class="co"># error_rate = mean of errors</span></span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>  np.random.seed(<span class="dv">1</span>)</span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a>  <span class="co"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Initialize list for errors</span></span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>  errors <span class="op">=</span> []</span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a>  <span class="co"># find # of examples</span></span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a>  size <span class="op">=</span> X.shape[<span class="dv">0</span>]</span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a>  <span class="co"># use split_nfold function to get training and val sets</span></span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a>  train_sets, val_sets <span class="op">=</span> split_nfold(size, n)</span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a>  <span class="co"># get corresponding value of X related to train and val sets</span></span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a>    train_index <span class="op">=</span> train_sets[i]</span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a>    val_index <span class="op">=</span> val_sets[i]</span>
<span id="cb8-51"><a href="#cb8-51" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-52"><a href="#cb8-52" aria-hidden="true" tabindex="-1"></a>    <span class="co"># get the training and validation sets of input features from X</span></span>
<span id="cb8-53"><a href="#cb8-53" aria-hidden="true" tabindex="-1"></a>    X_train, X_val <span class="op">=</span> X[train_index], X[val_index]</span>
<span id="cb8-54"><a href="#cb8-54" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-55"><a href="#cb8-55" aria-hidden="true" tabindex="-1"></a>    <span class="co"># get the training and validation labels from Y</span></span>
<span id="cb8-56"><a href="#cb8-56" aria-hidden="true" tabindex="-1"></a>    y_train, y_val <span class="op">=</span> Y[train_index], Y[val_index]</span>
<span id="cb8-57"><a href="#cb8-57" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-58"><a href="#cb8-58" aria-hidden="true" tabindex="-1"></a>    <span class="co"># call the classifier to get prediction results for the current validation set</span></span>
<span id="cb8-59"><a href="#cb8-59" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> classifier(X_val, X_train, y_train, <span class="op">*</span>args)</span>
<span id="cb8-60"><a href="#cb8-60" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-61"><a href="#cb8-61" aria-hidden="true" tabindex="-1"></a>    <span class="co"># call compute_error_rate to compute the error rate by comparing ypred against y_val</span></span>
<span id="cb8-62"><a href="#cb8-62" aria-hidden="true" tabindex="-1"></a>    error <span class="op">=</span> compute_error_rate(y_pred, y_val)</span>
<span id="cb8-63"><a href="#cb8-63" aria-hidden="true" tabindex="-1"></a>    errors.append(error)</span>
<span id="cb8-64"><a href="#cb8-64" aria-hidden="true" tabindex="-1"></a>  <span class="co"># error_rate = mean of errors</span></span>
<span id="cb8-65"><a href="#cb8-65" aria-hidden="true" tabindex="-1"></a>  error_rate <span class="op">=</span> <span class="bu">sum</span>(errors)<span class="op">/</span><span class="bu">len</span>(errors)</span>
<span id="cb8-66"><a href="#cb8-66" aria-hidden="true" tabindex="-1"></a>  <span class="co"># *****</span><span class="re">END</span><span class="co"> OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span>
<span id="cb8-67"><a href="#cb8-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-68"><a href="#cb8-68" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> error_rate </span>
<span id="cb8-69"><a href="#cb8-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-70"><a href="#cb8-70" aria-hidden="true" tabindex="-1"></a><span class="co"># Unit test code here (you can uncomment the lines below to test)</span></span>
<span id="cb8-71"><a href="#cb8-71" aria-hidden="true" tabindex="-1"></a>X_dataset <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">0</span>, <span class="dv">3</span>], [<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>], [<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>], [<span class="dv">2</span>, <span class="dv">1</span>]])</span>
<span id="cb8-72"><a href="#cb8-72" aria-hidden="true" tabindex="-1"></a>Y_dataset <span class="op">=</span> np.array([<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>])</span>
<span id="cb8-73"><a href="#cb8-73" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb8-74"><a href="#cb8-74" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb8-75"><a href="#cb8-75" aria-hidden="true" tabindex="-1"></a>cross_validation(knn_predict, X_dataset, Y_dataset, n, k)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>40.0</code></pre>
</div>
</div>
<p>Side note: instead of <code>for i in range(n):</code>, you can also use</p>
<p><code>for (train_index, val_index) in zip(train_sets, val_sets):</code></p>
<p>Try it if you like as it can be more generic. No need to submit anything for it.</p>
</section>
</section>
<section id="problem-2-optical-character-recognition-ocr-18-points" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="problem-2-optical-character-recognition-ocr-18-points">Problem 2: Optical character recognition (OCR) <strong>(18 points)</strong></h2>
<p>We will now apply the above developed function to a real world problem of optical character recognition (OCR).</p>
<p><strong>Load the MNIST dataset.</strong> In the following code block, we have downloaded the MNIST dataset and split the data into trainning and test sets. This part has already been done, and you can directly run it with no need of modifying the code. But do make sure that you understand the code as it will be useful for future labs.</p>
<p><strong>Note:</strong> after running the code, the training data (Xtrain, ytrain) has 10,000 examples, and the test data (Xtest, ytest) also has 10,000 examples.</p>
<div class="cell" data-tags="[]" data-execution_count="8">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gzip</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>DATA_URL <span class="op">=</span> <span class="st">'https://www.cs.uic.edu/~zhangx/teaching/'</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Download and import the MNIST dataset from Yann LeCun's website.</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Each image is an array of 784 (28x28) float values  from 0 (white) to 1 (black).</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_data():</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    x_tr <span class="op">=</span> load_images(<span class="st">'train-images-idx3-ubyte.gz'</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    y_tr <span class="op">=</span> load_labels(<span class="st">'train-labels-idx1-ubyte.gz'</span>)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    x_te <span class="op">=</span> load_images(<span class="st">'t10k-images-idx3-ubyte.gz'</span>)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    y_te <span class="op">=</span> load_labels(<span class="st">'t10k-labels-idx1-ubyte.gz'</span>)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x_tr, y_tr, x_te, y_te</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_images(filename):</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>    maybe_download(filename)</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> gzip.<span class="bu">open</span>(filename, <span class="st">'rb'</span>) <span class="im">as</span> f:</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>        data <span class="op">=</span> np.frombuffer(f.read(), np.uint8, offset<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">28</span> <span class="op">*</span> <span class="dv">28</span>) <span class="op">/</span> np.float32(<span class="dv">256</span>)</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_labels(filename):</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>    maybe_download(filename)</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> gzip.<span class="bu">open</span>(filename, <span class="st">'rb'</span>) <span class="im">as</span> f:</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>        data <span class="op">=</span> np.frombuffer(f.read(), np.uint8, offset<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Download the file, unless it's already here.</span></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> maybe_download(filename):</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> os.path.exists(filename):</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>        <span class="im">from</span> urllib.request <span class="im">import</span> urlretrieve</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Downloading </span><span class="sc">%s</span><span class="st">"</span> <span class="op">%</span> filename)</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>        urlretrieve(DATA_URL <span class="op">+</span> filename, filename)</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>Xtrain, ytrain, Xtest, ytest <span class="op">=</span> load_data()</span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>train_size <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>test_size  <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>Xtrain <span class="op">=</span> Xtrain[<span class="dv">0</span>:train_size]</span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a>ytrain <span class="op">=</span> ytrain[<span class="dv">0</span>:train_size]</span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a>Xtest <span class="op">=</span> Xtest[<span class="dv">0</span>:test_size]</span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a>ytest <span class="op">=</span> ytest[<span class="dv">0</span>:test_size]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="effect-of-different-number-of-cross-validation-folds-18-points" class="level3">
<h3 class="anchored" data-anchor-id="effect-of-different-number-of-cross-validation-folds-18-points">2.1 Effect of different number of cross validation folds <strong>(18 points)</strong></h3>
<p>In the following code block, we will perform cross validation on 1-NN classification. Call the <code>knn_predict</code> and <code>cross_validation</code> functions you have implemented, and compute the cross validation error rate for the first <strong>1000</strong> training examples with different number of folds <span class="math inline">\(n \in \{3, 10, 50, 100, 1000\}\)</span>. Then <strong>print</strong> the error rate for each different <span class="math inline">\(n\)</span> and <strong>plot</strong> a figure where the <span class="math inline">\(x\)</span>-axis is <span class="math inline">\(n = \{3, 10, 50, 100, 1000\}\)</span>, and the <span class="math inline">\(y\)</span>-axis is the <span class="math inline">\(n\)</span>-fold cross validation error rate.</p>
<p><strong>Note about terminology:</strong> In Problem 1, we used the term <em>dataset</em>, and the <span class="math inline">\(n\)</span>-fold partitioning was on the <em>dataset</em>. Now in the current setting, these <strong>1000</strong> training examples correspond to the <em>dataset</em>. In other words, this Section 2.2 will <strong>not</strong> use the test examples loaded from Problem 2, nor the remaining <span class="math inline">\(10000 - 1000 = 9000\)</span> training examples.</p>
<div class="cell" data-tags="[]" data-execution_count="80">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>size <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Here is the pseudo code:</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># get the feature/label of the first 'size' (i.e., 1000) number of training examples</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="co"># cvXtrain = Xtrain[...]  </span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="co"># cvytrain = ytrain[...]  </span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="co"># trial_folds   = [3, 10, 50, 100, 1000]</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="co"># trials = number of trials on #folds, i.e., get the length of trial_folds (=5)</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="co"># cverror_rates = [0]*trials</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="co"># for t = 0 ... trials-1</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="co">#   error_rate = # call the 'cross_validation' function to get the error rate </span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="co">#                #  for the current trial (of fold number)</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a><span class="co">#   cverror_rates[t] = error_rate</span></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a><span class="co">#   # print the error rate for the current trial.</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a><span class="co">#   print('{:d}-folds error rate: {:.2f}%\n'.format(trial_folds[t], error_rate)) </span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the figure:</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a><span class="co"># f = plt.figure()</span></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.plot(...)</span></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.xlabel(...)</span></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.ylabel(...)</span></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.show()</span></span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a><span class="co"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a><span class="co"># retrieve 1000 training examples</span></span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>cvXtrain <span class="op">=</span> Xtrain[:size]</span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>cvytrain <span class="op">=</span> ytrain[:size]</span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a><span class="co"># define folds</span></span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>trial_folds <span class="op">=</span> [<span class="dv">3</span>,<span class="dv">10</span>,<span class="dv">50</span>,<span class="dv">100</span>,<span class="dv">1000</span>]</span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a>trials <span class="op">=</span> <span class="bu">len</span>(trial_folds)</span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>cverror_rates <span class="op">=</span> [<span class="dv">0</span>]<span class="op">*</span>trials</span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(trials):</span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>    error_rate <span class="op">=</span> cross_validation(knn_predict, cvXtrain, cvytrain, trial_folds[t], k)</span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a>    cverror_rates[t] <span class="op">=</span> error_rate</span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'</span><span class="sc">{:d}</span><span class="st">-folds error rate: </span><span class="sc">{:.2f}</span><span class="st">%</span><span class="ch">\n</span><span class="st">'</span>.<span class="bu">format</span>(trial_folds[t], error_rate))</span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the figure:</span></span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> plt.figure()</span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a>plt.plot(trial_folds, cverror_rates)</span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"trial fold size"</span>)</span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"cross validation error rate"</span>)</span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-54"><a href="#cb11-54" aria-hidden="true" tabindex="-1"></a><span class="co"># *****</span><span class="re">END</span><span class="co"> OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>3-folds error rate: 12.70%

10-folds error rate: 12.00%

50-folds error rate: 12.10%

100-folds error rate: 11.90%

1000-folds error rate: 11.80%
</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="Lab_3_files/figure-html/cell-10-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="problem-3-iris-plant-recognition-46-point" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="problem-3-iris-plant-recognition-46-point">Problem 3: Iris plant recognition <strong>(46 point)</strong></h2>
<p>The iris dataset includes 3 iris species of 50 examples each, where each example recorded petal and sepal length. For convenience, we will use the built-in functions in <code>scikit-learn</code> library to load dataset and create data partitions. For this experiment, we will use <span class="math inline">\(80\%\)</span> (120) examples for training and <span class="math inline">\(20\%\)</span> (30) for testing.</p>
<p>Actually, we have done this data preparation work for you. You can directly use the training set (<em>X_train</em>, <em>Y_train</em>) and test set (<em>X_test</em>, <em>Y_test</em>) for the experiments, where <em>X</em> is features and <em>Y</em> is labels.</p>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_iris</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># loading iris dataset</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>iris <span class="op">=</span> load_iris()</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co"># split dataset into training set and test set</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>X_train, X_test, Y_train, Y_test <span class="op">=</span> train_test_split(iris.data, iris.target, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="find-the-best-k.-18-points" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="find-the-best-k.-18-points">3.1 Find the best <span class="math inline">\(k\)</span>. <strong>(18 points)</strong></h3>
<p>In Problem 2, we conducted the experiments by arbitrarily setting <span class="math inline">\(k\)</span> to 1. In fact, the value of <span class="math inline">\(k\)</span> has a considerable impact on the performance of kNN. We will now determine the best value of this hyperparameter with <span class="math inline">\(10\)</span>-fold cross-validation. To specify, we will vary <span class="math inline">\(k\)</span> in the range (1, 100) in increments of 1. Then we will find the best <span class="math inline">\(k\)</span> in terms of the lowest validation error rate. For this question, you need to: * <strong>(9 points)</strong> Store the validation error for each <span class="math inline">\(k\)</span> in an array and report the value of the best <span class="math inline">\(k\)</span>. * <strong>(9 points)</strong> Plot a curve that shows the validation error rates as <span class="math inline">\(k\)</span> increases.</p>
<p><strong>Note about terminology:</strong> In Problem 1, we used the term <em>dataset</em>, and the <span class="math inline">\(n\)</span>-fold partitioning was on the <em>dataset</em>. Now in the current setting, (X_strain, Y_train) loaded above correspond to the <em>dataset</em>. In other words, this Section 3.1 will <strong>not</strong> use the test examples loaded above.</p>
<div class="cell" data-tags="[]" data-execution_count="81">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Here is the pseudo code:</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co"># list_ks = 1,2,...,100</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co"># err_ks = 1D array of length 100</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># for k in list_ks:</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co">#   err_ks[k-1] = cross_validation under k </span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co"># best_k = argmin(err_ks)+1</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co"># plot err_ks versus list_ks</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>list_ks <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">1</span>,<span class="dv">101</span>))</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>err_ks <span class="op">=</span> [<span class="dv">0</span>]<span class="op">*</span><span class="dv">100</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>fold_size <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> list_ks:</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>    err_ks[k<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> cross_validation(knn_predict, X_train, Y_train, fold_size, k)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>best_k <span class="op">=</span> np.argmin(err_ks)<span class="op">+</span><span class="dv">1</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"best k:"</span>, best_k)</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>plt.plot(list_ks, err_ks)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'k value'</span>)</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'cross validation error rate'</span>)</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a><span class="co"># *****</span><span class="re">END</span><span class="co"> OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>best k: 9</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="Lab_3_files/figure-html/cell-12-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="evaluation-on-test-set-8-points" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="evaluation-on-test-set-8-points">3.2 Evaluation on test set <strong>(8 points)</strong></h3>
<p>Since we have found the best hyperparameters for kNN classifier, its time to evaluate this method on test data.</p>
<p><strong>Task (8 points):</strong> Report the classification error of kNN on test data, where <span class="math inline">\(k\)</span> is the optimal one from Section 3.1 (break tie arbitrarily).</p>
<div class="cell" data-tags="[]" data-execution_count="82">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Here is the pseudo code:</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="co"># y_pred = knn_predict on X_test using X_train, Y_train, and best_k</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co"># use compute_error_rate to compute the error of y_pred compared with Y_test</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the error rate with a line like 'The test error is x.y%'</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="co">#predict with knn_predict </span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> knn_predict(X_test, X_train, Y_train, best_k)</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="co"># compute and print test error</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>err_test <span class="op">=</span> compute_error_rate(y_pred, Y_test)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The test error is '</span>, err_test,<span class="st">'%'</span>)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="co"># *****</span><span class="re">END</span><span class="co"> OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The test error is  3.3333333333333335 %</code></pre>
</div>
</div>
</section>
<section id="f-score-measurement-20-points" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="f-score-measurement-20-points">3.3 F-score measurement <strong>(20 points)</strong></h3>
<p>So far we have mainly used classification accuracy to evaluate the performance of our model. As a performance measure, accuracy is inappropriate for imbalanced classification problems. An alternative is the F-score metrics.</p>
<p><strong>Tasks</strong> * <strong>(10 points)</strong> Implement the computation of the confusion matrix on test set using <code>y_test</code> and the prediction <code>y_pred</code> from Section 3.2. You can compare your result with the one computed by <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html">sklearn.metrics.confusion_matrix</a> to ensure your implementation is correct. * <strong>(4 points)</strong> Report the precision, recall, and F1-score for each class by using the built-in functions from <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html">sklearn.metrics.classification_report</a>. * <strong>(6 points)</strong> Write your own code to compute the F1-score for the three classes, and make sure they match the f1-score column of the sklearn result.</p>
<p><strong>Hint:</strong> All definitions of confusion matrix, precision, recall, and F1-score can be found in the slides for Chapter19: DESGN AND ANALYSS OF MACHNE LEARNNG EXPERMENTS.</p>
<div class="cell" data-tags="[]" data-execution_count="84">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>nclass <span class="op">=</span> <span class="bu">len</span>(np.unique(Y_test))  <span class="co"># should be 3. Just be more adaptive to data.</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> np.zeros((nclass, nclass), dtype<span class="op">=</span><span class="bu">int</span>)  <span class="co"># confusion matrix is integer valued</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Here is the pseudo code for Task 1: </span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co"># for t = 0...nte-1  # nte is the number of test examples</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co">#    cm[c1, c2] += 1  # c1 and c2 corresponds to the class of the t-th test example</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co">#                     # according to Y_test and y_pred, respectively</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Here is the pseudo code for Task 3:</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Well, please consult the textbook, as I really hope you can do it yourself,</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co"># especially when the right answer is provided by sklearn for comparison</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="co"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a><span class="co">#Task 1</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(Y_test)):</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>    c1 <span class="op">=</span> Y_test[t]</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>    c2 <span class="op">=</span> y_pred[t]</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>    cm[c1, c2] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cm)</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a><span class="co">#Task 2</span></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>cr <span class="op">=</span> classification_report(Y_test, y_pred)</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cr)</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a><span class="co">#Task 3</span></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>f1 <span class="op">=</span> [<span class="dv">0</span>]<span class="op">*</span>nclass</span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n <span class="kw">in</span> <span class="bu">range</span>(nclass):</span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>    <span class="co">#calculate precision</span></span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>    precision <span class="op">=</span> cm[n,n] <span class="op">/</span> cm.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">0</span>)[n] </span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>    <span class="co">#calculate recall</span></span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a>    recall <span class="op">=</span> cm[n,n] <span class="op">/</span> <span class="bu">sum</span>(cm[n])  </span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>    <span class="co">#calculate f1</span></span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>    f1[n] <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> (precision <span class="op">*</span> recall) <span class="op">/</span> (precision <span class="op">+</span> recall)</span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1)</span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a><span class="co"># *****</span><span class="re">END</span><span class="co"> OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[11  0  0]
 [ 0 12  1]
 [ 0  0  6]]
              precision    recall  f1-score   support

     class 0       1.00      1.00      1.00        11
     class 1       1.00      0.92      0.96        13
     class 2       0.86      1.00      0.92         6

    accuracy                           0.97        30
   macro avg       0.95      0.97      0.96        30
weighted avg       0.97      0.97      0.97        30

[1.0, 0.9600000000000001, 0.923076923076923]</code></pre>
</div>
</div>
</section>
</section>
<section id="submission-instruction" class="level1 unnumbered">
<h1 class="unnumbered">Submission Instruction</h1>
<p>Youre almost done! Take the following steps to finally submit your work.</p>
<ol type="1">
<li>After executing all commands and completing this notebook, save your <code>Lab_3.ipynb</code> as a PDF file, named as <code>X_Y_UIN.pdf</code>, where <code>X</code> is your first name, <code>Y</code> is your last name, and <code>UIN</code> is your UIN. Make sure that your PDF file includes all parts of your solution, including the plots.</li>
</ol>
<blockquote class="blockquote">
<ul>
<li>Print out all unit test case results before printing the notebook into a PDF.</li>
<li>If you use Colab, open this notebook in Chrome. Then File -&gt; Print -&gt; set Destination to Save as PDF. If the web page freezes when printing, close Chrome and reopen the page. If Chrome doesnt work, try Firefox.</li>
<li>If you are working on your own computer, we recommend using the browser (not jupyter) for saving the PDF. For Chrome on a Mac, this is under <em>File-&gt;Print-&gt;Open PDF in Preview</em>. When the PDF opens in Preview, you can use <em>Save</em> to save it.</li>
<li>Sometimes, a figure that appears near the end of a page can get cut. In this case, try to add some new lines in the preceding code block so that the figure is pushed to the beginning of the next page. Or insert some text blocks.</li>
</ul>
</blockquote>
<ol start="2" type="1">
<li><p>Upload <code>X_Y_UIN.pdf</code> to Gradescope under <code>Lab_3_Written</code>.</p></li>
<li><p>A template of <code>Lab_3.py</code> has been provided. For all functions in <code>Lab_3.py</code>, copy the corresponding code snippets you have written into it, excluding the plot code. <strong>Do NOT</strong> copy any code of plotting figures and do not import <strong>matplotlib</strong>. This is because the auto-grader cannot work with plotting. <strong>Do NOT</strong> change the function names.</p></li>
<li><p>Zip <code>Lab_3.py</code> and <code>Lab_3.ipynb</code> (<strong>2 files</strong>) into a zip file named <code>X_Y_UIN.zip</code>. Suppose the two files are in the folder <code>Lab_3</code>. Then zip up the <strong>two files inside the <code>Lab_3</code> folder</strong>. <strong>Do NOT zip up the folder <code>Lab_3</code></strong> because the auto-grader cannot search inside a folder. Submit this zip file to Gradescope under <code>Lab_3_Code</code>.</p></li>
<li><p>The autograder on Gradscope will be open all the time. We designed some simple test cases to help you check wehther your functions are executable. You will see the results of running autograder once you submit your code. Please follow the error messages to debug. Since those simple test cases are designed for debugging, it does not guaranttee your solution will work well on the real dataset. It is your responsibility to make your code logically correct. Since all functions are tested in batch, the autograder might take a few minutes to run after submission.</p></li>
</ol>
<p><font color="red">If you <em>only</em> try to get real-time feedback from auto-grader, it will be fine to just upload <code>Lab_3.py</code> to <code>Lab_3_Code</code></font>. However, the final submission for grading should still follow the above point 4.</p>
<p>You can submit to Gradescope as often as you like. We will only consider your last submission before the deadline.</p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>